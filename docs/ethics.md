# Ethics in EVE

EVE is a value framework.  
Ethics are not optional.

This document defines the **minimum ethical baseline** for EVE-aligned implementations.

---

## Core ethical commitments

### 1. Voluntary participation
Participation must always be opt-in.

No dark patterns.
No coercion.
No forced engagement.

---

### 2. Consent-first data use
Data must be:
- purpose-limited
- transparent
- revocable where possible

Users should understand:
- what is collected
- why it is collected
- how it is used

---

### 3. Proportional incentives
Rewards must be proportional to:
- value created
- verification strength
- potential for misuse

Avoid:
- over-rewarding
- addiction mechanics
- infinite accumulation loops

---

### 4. No permanent scoring of humans
EVE is not a reputation system.

Avoid:
- global rankings
- immutable scores
- identity-bound value histories

Value signals should be contextual and time-bound.

---

### 5. Anti-surveillance by design
EVE prefers:
- explicit signals over passive tracking
- participation over extraction
- trust over monitoring

If surveillance is required for a use case, EVE may not be appropriate.

---

### 6. Right to disengage
Participants must be able to:
- stop participating
- leave without penalty
- avoid lock-in

EVE should not trap people in systems.

---

## Ethical tension is expected

Some trade-offs are unavoidable:
- incentives vs intrinsic motivation
- verification vs privacy
- visibility vs safety

EVE does not promise perfect solutions — only transparent ones.

When in doubt:
- choose the option that preserves agency
- prefer reversibility
- document the trade-off

---

## Ethical red lines

An implementation is **not EVE-aligned** if it:
- coerces participation
- monetizes attention deceptively
- extracts value without acknowledgment
- obscures incentives or verification
- treats humans as data exhaust

---

## Final principle

**EVE exists to make value visible — not to extract it.**

If an implementation feels exploitative, pause.
